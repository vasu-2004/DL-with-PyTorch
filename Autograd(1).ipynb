{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ig5OrUKSvMph",
        "outputId": "ee2cbfba-0ce3-4322-9ad2-c3acd86039d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 1.8111, -1.0581, -1.0703])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "x = torch.randn(3)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The requires_grad=True creates a compuatational graph"
      ],
      "metadata": {
        "id": "eGJrtG9Kv6Zh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x =torch.randn(3,requires_grad=True)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-v39HF6vjK5",
        "outputId": "2873cd9f-c666-48fd-97ae-af9bbeed7e8f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.8675, -1.1722, -0.0580], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = x+2"
      ],
      "metadata": {
        "id": "1-dPIaO5vx9B"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3QSuKnev3Kb",
        "outputId": "4f90b7d7-febc-4971-e95c-8603684901d3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2.8675, 0.8278, 1.9420], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = y*y\n",
        "z.grad_fn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaeYgJ7hwP5N",
        "outputId": "2b1881b0-83c7-4267-cbd8-554665a8b7b7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<MulBackward0 at 0x781fe960dde0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = z.mean()"
      ],
      "metadata": {
        "id": "ccPOsVTozrSi"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward() # dz/dx"
      ],
      "metadata": {
        "id": "vSbhNHAqLUz5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWJKXlA2Lcls",
        "outputId": "784e3240-71ae-47e9-9cb0-3a702399db02"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.9117, 0.5518, 1.2946])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "loss.backward() is a key method used in training machine learning models. It computes the gradients of the loss function with respect to all tensors in the computation graph that have requires_grad=True. These gradients are stored in the .grad attribute of the respective tensors"
      ],
      "metadata": {
        "id": "fW152SiKOPGV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Backward Pass:\n",
        "\n",
        "    When loss.backward() is called, PyTorch computes:\n",
        "    ∂loss∂xi=2n(xi−ytrue,i).\n",
        "    ∂xi​∂loss​=n2​(xi​−ytrue,i​).\n",
        "\n",
        "Gradient Output: The .grad attribute of xx contains the derivative:\n",
        "x.grad=2n(x−ytrue)\n",
        "x.grad=n2​(x−ytrue​)"
      ],
      "metadata": {
        "id": "tQeLL09jRJcN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = torch.tensor([1.0,2.1,3.0],)\n",
        "y_pred = torch.tensor([1.30,2.79,4.02],requires_grad=True)\n",
        "MSE = torch.mean((y_pred - y_true)**2)\n",
        "MSE.backward()\n",
        "print(y_pred.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOT9qBnkMEEo",
        "outputId": "f573e13b-c93e-4ab3-b799-be72eec32178"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.2000, 0.4600, 0.6800])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v = torch.tensor([1,10,100],dtype=torch.float32)\n",
        "SR = (y_pred - y_true)**2\n",
        "SR.backward(v)\n",
        "\n",
        "print(y_pred.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-impSADPoz3",
        "outputId": "5e28a764-6aa1-4ae3-b352-55387b6f841b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([  0.8000,  14.2600, 204.6800])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([2.,3.,4.],requires_grad=True)\n",
        "y = x**2\n",
        "equal_gradients = torch.tensor([1.,1.,1.],dtype=torch.float32)\n",
        "y.backward(equal_gradients)\n",
        "print(\"Equal gradients\",x.grad)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuSGkqvFUcgx",
        "outputId": "6af242cf-b54b-47bb-c591-c81f932dde04"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Equal gradients tensor([4., 6., 8.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([2.,3.,4.],requires_grad=True)\n",
        "y = x**2\n",
        "gradients = torch.tensor([1.,.1,.01],dtype=torch.float32)\n",
        "\n",
        "y.backward(gradients)\n",
        "print(\"Weighted Gradients\",x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_tTtzpuVrr5",
        "outputId": "bb72ef0f-4e71-4dca-c2b5-b430b7d2ee60"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weighted Gradients tensor([4.0000, 0.6000, 0.0800])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.requires_grad_(False)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PC2AJjgmYAzt",
        "outputId": "51c96473-c19a-4f0b-beef-c81650c01d76"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2., 3., 4.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.tensor([1,2,3],requires_grad=True,dtype=torch.float32)\n",
        "print(t)\n",
        "t0 = t.detach()\n",
        "print(t0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrLwnzkHY8vm",
        "outputId": "c435d11c-eed8-490d-f46e-e9d4ff4d08d8"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 2., 3.], requires_grad=True)\n",
            "tensor([1., 2., 3.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The with torch.no_grad: context in PyTorch is used to temporarily disable gradient tracking. This is particularly useful for operations where you don't want to compute gradients, such as during inference, evaluation, or updating parameters manually without affecting the computation graph"
      ],
      "metadata": {
        "id": "m4PlB92ncdke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = t+2\n",
        "print(y)\n",
        "\n",
        "with torch.no_grad():\n",
        "    y = t+2\n",
        "    print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0trtF1ZZRzr",
        "outputId": "a115b422-cc55-47fa-85b6-ef2f57acca96"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3., 4., 5.], grad_fn=<AddBackward0>)\n",
            "tensor([3., 4., 5.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torch.ones(4,requires_grad=True)\n",
        "\n",
        "for epoch in range(3):\n",
        "    model_output = (weights*3).sum()\n",
        "    model_output.backward()\n",
        "    print(weights.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BNwsDiIZtFE",
        "outputId": "466edefc-a449-45f5-ac14-cd795b8a1902"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3., 3., 3., 3.])\n",
            "tensor([6., 6., 6., 6.])\n",
            "tensor([9., 9., 9., 9.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How Accumulation Happens\n",
        "\n",
        "    During Backward Pass:\n",
        "        When you call loss.backward(), PyTorch computes the gradients for each parameter with respect to the loss and adds these gradients to the existing values in .grad.\n",
        "\n",
        "    Addition Instead of Replacement:\n",
        "        PyTorch does not overwrite the .grad attribute during backpropagation. Instead, it adds the new gradients to the existing ones."
      ],
      "metadata": {
        "id": "i2cfIl3Yb5ml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torch.ones(4,requires_grad=True)\n",
        "\n",
        "for epoch in range(3):\n",
        "    model_output = (weights*3).sum()\n",
        "    model_output.backward()\n",
        "    print(weights.grad)\n",
        "    weights.grad.zero_() #resets the weights fo the next iteration"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QczkH9itaU_9",
        "outputId": "5d6df784-1ca6-492b-9edf-6eb3cea94618"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G405SWf_aiT6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}